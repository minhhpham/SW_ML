{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acc5f3be-27c9-470c-afaf-e997708dae25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizers.vocab import create_NGram_vocab\n",
    "from tokenizers.NGram import nGram_tokenize\n",
    "from models.Transformer import Transformer\n",
    "from training.preprocess import batch_load_and_preprocess\n",
    "from data.loader import read_data\n",
    "from data.generate import SmithWaterman\n",
    "import timeit\n",
    "\n",
    "MODEL_PATH = \"saved_models/Transformer_4.pt\"\n",
    "MODEL_SIZE = 512\n",
    "INPUT_DIM = 24\n",
    "PAD_TOKEN = \"0000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2c32588-9b8b-4946-8bbc-282e24c0ff3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "vocab_4gram = create_NGram_vocab(4)\n",
    "model = Transformer(\n",
    "    vocab_size=len(vocab_4gram),\n",
    "    stack_size=4,\n",
    "    d_model=MODEL_SIZE,\n",
    "    d_feed_fwd=2048,\n",
    "    n_attn_heads=8,\n",
    "    dropout=0.1\n",
    ")\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3059a609-5087-4300-a7f8-a47d238438e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data  /data/minhpham/SW-ML-data/SRR622461\n",
      "    loading file  /data/minhpham/SW-ML-data/SRR622461_10\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "data = list(\n",
    "    read_data(\n",
    "        path=\"/data/minhpham/SW-ML-data/SRR622461\",\n",
    "        sample_limit=1000,\n",
    "        start_part=10,\n",
    "        part_limit=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a148f889-05ed-4668-997d-51be567f04fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(seq1: str, seq2: str):\n",
    "    tokens1 = nGram_tokenize(seq1)\n",
    "    tokens2 = nGram_tokenize(seq2)\n",
    "    tokens1 = tokens1[:INPUT_DIM]  # trim long seqs\n",
    "    tokens2 = tokens2[:INPUT_DIM]\n",
    "    # pad short seqs\n",
    "    if len(tokens1) < INPUT_DIM:\n",
    "        tokens1 = tokens1 + (INPUT_DIM - len(tokens1)) * [PAD_TOKEN]\n",
    "        tokens2 = tokens2 + (INPUT_DIM - len(tokens2)) * [PAD_TOKEN]\n",
    "\n",
    "    x1 = torch.tensor(vocab_4gram.lookup_indices(tokens1), dtype=torch.int32).unsqueeze(0)\n",
    "    x2 = torch.tensor(vocab_4gram.lookup_indices(tokens2), dtype=torch.int32).unsqueeze(0)\n",
    "    mask = (torch.logical_or(x1 != 0, x2 != 0)).unsqueeze(-2)\n",
    "    y_hat = model(x1, x2, mask)\n",
    "    return y_hat.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2644d04e-f324-40c7-9d74-359c58f0d9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "predicted score  95.99535369873047\n",
      "real score       96\n",
      "Smith-Waterman latency  : 0.04 ms\n",
      "Machine Learning latency: 8.81 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTTCATAGAGGCAAGGGAACTTCCCAAGGACACACAGCACCTAAGCGGCCGAGTCAGTGCAGCTCCTGCACATACCTAACCCTCCGTCCGATTC\n",
      "predicted score  82.65046691894531\n",
      "real score       80\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.92 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTTCTGAGGGGCTAGGGAACGACACAAAGACAAACAGCACCTAAGAAGCCGAGTCGGTGCTGCTCCCACACACACCTTACCCTCCTTCCCATGC\n",
      "predicted score  70.09864044189453\n",
      "real score       66\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.85 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "ACGTTCAGAGAGGGTAGGGTACATCCTAAGGCCTCACAGCGCCTTGTGAGCCGAGTCAGTCCAGCTTCTGACCACAGCCTGCCCTCTGTCCCATTC\n",
      "predicted score  65.00791931152344\n",
      "real score       59\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.85 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGATCAGTGCGGGTCGGGTAACTCCCAAGCACACCCGGCACCTAGGACTCCCAGTCCGTGCAGTCCCGGTAGCTACGCGATCCTCCGTCCTTTTC\n",
      "predicted score  62.298885345458984\n",
      "real score       41\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.86 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTGGATGGATCTTTTGGATCAACTCAAAGAGCTATTCCGACTAGGAGGCCCAGTCAGGGCAGCTCTAGAACATAGCTTACACTCGGAAGCATTA\n",
      "predicted score  60.863956451416016\n",
      "real score       30\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.85 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGCTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTCGAGCTCCTTGCACACACCTTACCCTCCGTCCCAT\n",
      "predicted score  46.586360931396484\n",
      "real score       86\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.87 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGCTTCAGAGAGGCTAGGGAACATCCTAGCGACACCAGCACCTAGGAGGCCGAGTCACTGACAGCTCCCTGACACACCTAACCCTCCGTCCCATTC\n",
      "predicted score  65.30372619628906\n",
      "real score       74\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.85 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AAGGTCACCGAGGCCAGGGAACAACCCCAAGGAAACCCACCACGTAGGAGGCCGGGTCAGTGCAGATCATGCACACACCTTACCCCTCTGTCCCAC\n",
      "predicted score  47.64488983154297\n",
      "real score       62\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.97 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGTTTCAGAGAGGCTAAGGTGCCATCCCAAAAACACACAGGCCCGAGGTAGGCGGGGTCAGTGCAGCTCCCTGCACACCCCTTACTTTAGTTGCAT\n",
      "predicted score  55.890281677246094\n",
      "real score       52\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.89 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTCTCAGAGCGGCTAGGGAAAATGCTCGAGGACGCCCAACACGTAGGAGGTATGGTCAGTAACCTCCTTCTAACACCATGACCTGACTCGTATC\n",
      "predicted score  33.80134963989258\n",
      "real score       38\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.88 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGACCAGAGCGCCTACCGTGATATCCCATCCGCACACAGCACCTTGGAGAGCCAGGAGTGCAGTATCGCCATGAACTCACCATCCGCTCATTC\n",
      "predicted score  50.33815383911133\n",
      "real score       31\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.87 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGGTTTCAGAGAGCGTAGGGAACATTCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACCACCTTACCCTCCGATCCC\n",
      "predicted score  50.993202209472656\n",
      "real score       80\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.89 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "ATTCAGAGGGCTAGGGACCATCCCGAGAGAACCCCCAGCACCTCGGAGACCGAGTCAGTGCAGCTCCCTGCTACATACCTAACCCTCCGTCCCATT\n",
      "predicted score  62.24911117553711\n",
      "real score       65\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 8.92 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "TGGTACGAAGAAGCTAGTCAACTTCCCAAGGCCACAGCACCCAGGATGCCCAGTCAGTTCAGGCTACCGCACACACCGTACCCGTCCGTCCCATTC\n",
      "predicted score  46.102081298828125\n",
      "real score       57\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 9.05 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "TAGTTCAGAGAGCCTACTCCAACTTCGTTACGACAACTGCGCTTAGAGTGCACGTAGGCAGAGCATAGCCTGGCACACAACCTCACCCTCCGTCCC\n",
      "predicted score  41.0343132019043\n",
      "real score       36\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 9.27 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "TTGTTCTGATGGGCACGACATCACTAAAGACGAACCGTACCAAGAAGACTAGTCAGTTCAGCACCTGGCAGACACGTGACCACCCGTAACATAC\n",
      "predicted score  44.42100524902344\n",
      "real score       30\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 9.11 ms\n",
      "--------------------------------------------------------------------------------------------------\n",
      "AGGTTCAGAGAGGCTAGGGAACATCCCAAGGACACACAGCACCTAGGAGGCCGAGTCAGTGCAGCTCCTGCACACACCTTACCCTCCGTCCCATTC\n",
      "AGTAACCTACAGGATAGGGTCACCCGAGGCCACACGCACCAAGATGAAGATCATTGCCACTCCTGTACACTATCTTAGCCTTCAGCTCCTATTC\n",
      "predicted score  40.023983001708984\n",
      "real score       33\n",
      "Smith-Waterman latency  : 0.03 ms\n",
      "Machine Learning latency: 9.01 ms\n"
     ]
    }
   ],
   "source": [
    "for sample_id in range(18):\n",
    "    print(\"--------------------------------------------------------------------------------------------------\")\n",
    "    seq1 = data[sample_id][0]\n",
    "    seq2 = data[sample_id][1]\n",
    "    print(seq1)\n",
    "    print(seq2)\n",
    "    print(\"predicted score \", predict(seq1, seq2))\n",
    "    print(\"real score      \", SmithWaterman(seq1, seq2))\n",
    "    SW_latency = timeit.timeit(\"SmithWaterman(seq1, seq2)\", globals=globals(), number=1000)\n",
    "    ML_latency = timeit.timeit(\"predict(seq1, seq2)\", globals=globals(), number=1000)\n",
    "    print(\"Smith-Waterman latency  : {0:.2f} ms\".format(SW_latency))\n",
    "    print(\"Machine Learning latency: {0:.2f} ms\".format(ML_latency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba215df-457d-4f16-9a2d-8e23b5584aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbfb2b-82fb-4e24-8c67-8663f0eafed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
